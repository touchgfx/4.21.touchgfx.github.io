"use strict";(self.webpackChunktouchgfx_documentation=self.webpackChunktouchgfx_documentation||[]).push([[9494],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return d}});var r=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),h=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=h(e.components);return r.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},u=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),u=h(n),d=a,m=u["".concat(s,".").concat(d)]||u[d]||c[d]||o;return n?r.createElement(m,i(i({ref:t},p),{},{components:n})):r.createElement(m,i({ref:t},p))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,i=new Array(o);i[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,i[1]=l;for(var h=2;h<o;h++)i[h]=n[h];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}u.displayName="MDXCreateElement"},22425:function(e,t,n){var r=n(67294);class a extends r.Component{render(){return r.createElement("div",{className:"code-header"},r.createElement("div",null,r.createElement("h5",null,this.props.children)))}}t.Z=a},44035:function(e,t,n){var r=n(67294),a=n(25026);t.Z=function(e){const t=e.noShadow||!1,n=e.width,o=e.height,i=(0,a.Z)(e.imageSource);return t?r.createElement("div",{className:"figure noshadow"},r.createElement("a",{href:i,target:"_blank"},r.createElement("img",{width:n,height:o,src:i})),r.createElement("p",null,e.children)):r.createElement("div",{className:"figure"},r.createElement("a",{href:i,target:"_blank"},r.createElement("img",{width:n,height:o,src:i})),r.createElement("p",null,e.children))}},29415:function(e,t,n){var r=n(67294),a=n(88678);const o=r.createElement("svg",{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},r.createElement("path",{fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}));class i extends r.Component{render(){return r.createElement(a.Z,{color:"var(--highlight-color-further-reading)",header:"Further reading",type:"further-reading",icon:o},this.props.children)}}t.Z=i},88678:function(e,t,n){var r=n(67294);class a extends r.Component{render(){const e=`highlight highlight-${this.props.type}`;return r.createElement("div",{className:e},r.createElement("div",{className:"highlight-heading"},r.createElement("h5",null,r.createElement("div",{className:"highlight-icon"},this.props.icon),this.props.header)),r.createElement("div",{className:"highlight-content"},this.props.children))}}t.Z=a},37793:function(e,t,n){var r=n(67294),a=n(88678);const o=r.createElement("svg",{xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},r.createElement("path",{fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"}));class i extends r.Component{render(){return r.createElement(a.Z,{color:"var(--highlight-color-tip)",header:"Tip",type:"tip",icon:o},this.props.children)}}t.Z=i},58066:function(e,t,n){n.r(t),n.d(t,{assets:function(){return v},contentTitle:function(){return k},default:function(){return N},frontMatter:function(){return y},metadata:function(){return b},toc:function(){return T}});var r=n(3905),a=n(44035),o=n(37793),i=n(22425),l=n(29415),s=n(39130),h=Object.defineProperty,p=Object.defineProperties,c=Object.getOwnPropertyDescriptors,u=Object.getOwnPropertySymbols,d=Object.prototype.hasOwnProperty,m=Object.prototype.propertyIsEnumerable,f=(e,t,n)=>t in e?h(e,t,{enumerable:!0,configurable:!0,writable:!0,value:n}):e[t]=n,g=(e,t)=>{for(var n in t||(t={}))d.call(t,n)&&f(e,n,t[n]);if(u)for(var n of u(t))m.call(t,n)&&f(e,n,t[n]);return e};const y={id:"touchgfx-architecture",title:"Abstraction Layer Architecture",sidebar_label:"Abstraction Layer Architecture"},k=void 0,b={unversionedId:"development/touchgfx-hal-development/touchgfx-architecture",id:"development/touchgfx-hal-development/touchgfx-architecture",title:"Abstraction Layer Architecture",description:"",source:"@site/docs/development/touchgfx-hal-development/touchgfx-architecture.mdx",sourceDirName:"development/touchgfx-hal-development",slug:"/development/touchgfx-hal-development/touchgfx-architecture",permalink:"/4.21/ko/docs/development/touchgfx-hal-development/touchgfx-architecture",draft:!1,tags:[],version:"current",frontMatter:{id:"touchgfx-architecture",title:"Abstraction Layer Architecture",sidebar_label:"Abstraction Layer Architecture"},sidebar:"docs",previous:{title:"TouchGFX AL Development Introduction",permalink:"/4.21/ko/docs/development/touchgfx-hal-development/touchgfx-al-development-introduction"},next:{title:"Generator User Guide",permalink:"/4.21/ko/docs/category/generator-user-guide"}},v={},T=[{value:"Abstraction Layer Classes",id:"abstraction-layer-classes",level:3},{value:"Synchronize TouchGFX Engine main loop with display transfer",id:"synchronize-touchgfx-engine-main-loop-with-display-transfer",level:2},{value:"Rendering Done",id:"rendering-done",level:3},{value:"Display ready",id:"display-ready",level:3},{value:"Report touch and physical button events",id:"report-touch-and-physical-button-events",level:2},{value:"Touch Coordinates",id:"touch-coordinates",level:3},{value:"Other External Events",id:"other-external-events",level:3},{value:"Synchronize framebuffer access",id:"synchronize-framebuffer-access",level:2},{value:"Report the next available framebuffer area",id:"report-the-next-available-framebuffer-area",level:2},{value:"Perform Render Operations",id:"perform-render-operations",level:2},{value:"Handle framebuffer transfer to display",id:"handle-framebuffer-transfer-to-display",level:2},{value:"Rendering of area complete",id:"rendering-of-area-complete",level:3}],w={toc:T};function N(e){var t,n=e,{components:h}=n,f=((e,t)=>{var n={};for(var r in e)d.call(e,r)&&t.indexOf(r)<0&&(n[r]=e[r]);if(null!=e&&u)for(var r of u(e))t.indexOf(r)<0&&m.call(e,r)&&(n[r]=e[r]);return n})(n,["components"]);return(0,r.kt)("wrapper",(t=g(g({},w),f),p(t,c({components:h,mdxType:"MDXLayout"}))),(0,r.kt)("p",null,"As described in the previous section, the TouchGFX AL has a particular set of responsibilities.\nResponsibilities are either implemented in the hardware part of the AL (HAL) or the part of the\nAL that synchronizes with TouchGFX Engine, typically through an RTOS (OSAL). The following table\nsummarizes these responsibilities which were outlined in the previous section:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",g({parentName:"tr"},{align:null}),"Responsibility"),(0,r.kt)("th",g({parentName:"tr"},{align:null}),"Operating system or Hardware"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",g({parentName:"tr"},{align:null}),(0,r.kt)("a",g({parentName:"td"},{href:"#synchronize-touchgfx-engine-main-loop-with-display-transfer"}),"Synchronize TouchGFX Engine main loop with display transfer")),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"Operating system and hardware")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",g({parentName:"tr"},{align:null}),(0,r.kt)("a",g({parentName:"td"},{href:"#report-touch-and-physical-button-events"}),"Report touch and physical button events")),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"Hardware")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",g({parentName:"tr"},{align:null}),(0,r.kt)("a",g({parentName:"td"},{href:"#synchronize-framebuffer-access"}),"Synchronize framebuffer access")),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"Operating system")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",g({parentName:"tr"},{align:null}),(0,r.kt)("a",g({parentName:"td"},{href:"#report-the-next-available-framebuffer-area"}),"Report the next available framebuffer area")),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"Hardware")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",g({parentName:"tr"},{align:null}),(0,r.kt)("a",g({parentName:"td"},{href:"#perform-render-operations"}),"Perform render operations")),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"Hardware")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",g({parentName:"tr"},{align:null}),(0,r.kt)("a",g({parentName:"td"},{href:"#handle-framebuffer-transfer-to-display"}),"Handle framebuffer transfer to display ")),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"Hardware")))),(0,r.kt)("p",null,"Each of the following subsections highlight what should be done to fulfill the above responsibilities.\nFor custom hardware platforms the TouchGFX Generator, inside STM32CubeMX, can generate most of the AL\nand accompanying TouchGFX project. The remaining parts, that the AL developer must implement manually,\nare pointed out through code comments and notifications through the TouchGFX Generator. ",(0,r.kt)("a",g({parentName:"p"},{href:"generator-how-to/enabling-touchgfx-generator"}),"Read more"),"\nabout the TouchGFX Generator in the next section."),(0,r.kt)("h3",g({},{id:"abstraction-layer-classes"}),"Abstraction Layer Classes"),(0,r.kt)("p",null,"The TouchGFX AL is accessed by the TouchGFX Engine through concrete sub-classes and through class implementation files (.cpp)\nwhere member functions of classes defined in the TouchGFX Engine are implemented. These sub-classes and class implementation\nfiles are generated by the TouchGFX Generator.  The TouchGFX Generator can generate both the part of the HAL that reflects\nconfigurations from STM32CubeMX, as well as the OSAL for the used RTOS. Please read the section on ",(0,r.kt)("a",g({parentName:"p"},{href:"generator-how-to/enabling-touchgfx-generator"}),"TouchGFX Generator"),"\nfor further details. Generally, the architecture of the HAL is in the following figure."),(0,r.kt)(a.Z,{imageSource:"/img/development/touchgfx-hal-development/code-architecture.png",noShadow:!0,width:"200",mdxType:"Figure"},"Hierarchy of generated code"),(0,r.kt)("h2",g({},{id:"synchronize-touchgfx-engine-main-loop-with-display-transfer"}),"Synchronize TouchGFX Engine main loop with display transfer"),(0,r.kt)("p",null,"The main idea behind this step is to block the TouchGFX Engine main loop when rendering is done, ensuring\nthat no further frames are produced. Once the display is ready the OSAL signals the blocked Engine main loop to continue producing frames."),(0,r.kt)("p",null,"In order to fulfill this responsibility the typical way of a TouchGFX AL is to utilize the engine hook ",(0,r.kt)("em",{parentName:"p"},"Rendering done"),"\nand the interrupt ",(0,r.kt)("em",{parentName:"p"},"Display Ready"),", as outlined in ",(0,r.kt)("a",g({parentName:"p"},{href:"touchgfx-al-development-introduction#responsibilities-of-the-abstraction-layer"}),"Responsibilities of the Abstraction Layer"),".\nThe OSAL defines a function ",(0,r.kt)("inlineCode",{parentName:"p"},"OSWrappers::signalVSync")," in which developers can signal the semaphore that the engine\nwaits upon when called."),(0,r.kt)(o.Z,{mdxType:"Tip"},"The TouchGFX Generator can create a complete OSAL for CMSIS V1, CMSIS V2, ThreadX and when not using an RTOS."),(0,r.kt)("h3",g({},{id:"rendering-done"}),"Rendering Done"),(0,r.kt)("p",null,"The ",(0,r.kt)("em",{parentName:"p"},"Rendering done")," hook, ",(0,r.kt)("inlineCode",{parentName:"p"},"OSWrappers::waitForVSync"),", is called by the TouchGFX Engine after rendering is complete."),(0,r.kt)("p",null,"When implementing this OSAL method, the Abstraction Layer must block the graphics engine until it is time to render the next frame.\nThe standard method to implement this block is to perform a blocking read from a message queue. The HAL developer\nis free to use any method to implement the block if this is not feasible."),(0,r.kt)(o.Z,{mdxType:"Tip"},"The TouchGFX Generator can also generate an empty OSAL that uses spinlocks to wait, rather than RTOS primitives if such software is not available."),(0,r.kt)("p",null,"When ",(0,r.kt)("inlineCode",{parentName:"p"},"OSWrappers::signalVSync")," is signaled (or the semaphore/queue used in ",(0,r.kt)("inlineCode",{parentName:"p"},"OSWrappers::waitForVSync")," is signaled) TouchGFX will start\nrendering the next application frame. The following code based on CMSIS V2 causes the TouchGFX engine to block until an element is\nadded to the queue by another part of the system, typically an interrupt synchronized with the display."),(0,r.kt)(i.Z,{mdxType:"CodeHeader"},"OSWrappers.cpp (CMSIS V2)"),(0,r.kt)("pre",null,(0,r.kt)("code",g({parentName:"pre"},{className:"language-cpp"}),"static osMessageQueueId_t vsync_queue = NULL; //Queue identifier is assigned elsewhere\n\nvoid OSWrappers::waitForVSync()\n{\n    uint32_t dummyGet;\n    // First make sure the queue is empty, by trying to remove an element with 0 timeout.\n    osMessageQueueGet(vsync_queue, &dummyGet, 0, 0);\n\n    // Then, wait for next VSYNC to occur.\n    osMessageQueueGet(vsync_queue, &dummyGet, 0, osWaitForever);\n}\n")),(0,r.kt)("p",null,"If not using an RTOS, the TouchGFX Generator provides the following\nimplementation for ",(0,r.kt)("inlineCode",{parentName:"p"},"waitForVSync")," using a volatile variable."),(0,r.kt)(i.Z,{mdxType:"CodeHeader"},"OSWrappers.cpp (No OS)"),(0,r.kt)("pre",null,(0,r.kt)("code",g({parentName:"pre"},{className:"language-cpp"}),"static volatile uint32_t vsync_sem = 0;\n\nvoid OSWrappers::waitForVSync()\n{\n    if(vsync_sem)\n    {\n        vsync_sem = 0;\n        // Signal TouchGFX to start rendering next frame\n        ...\n    }\n}\n")),(0,r.kt)(o.Z,{mdxType:"Tip"},(0,r.kt)("li",null,(0,r.kt)("b",null,(0,r.kt)("i",null,"While"))," TouchGFX Engine is waiting to produce the next frame other tasks can do important work.")),(0,r.kt)("h3",g({},{id:"display-ready"}),"Display ready"),(0,r.kt)("p",null,"The ",(0,r.kt)("em",{parentName:"p"},"Display ready")," signal to unblock the main loop should come from an interrupt from a display controller,\nfrom the display itself or even from a hardware timer. The source of the signal is dependent on the type of display."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"OSWrappers")," class defines a function for this signal: ",(0,r.kt)("inlineCode",{parentName:"p"},"OSWrappers::signalVsync"),". The implementation\nof the function must unblock the main loop by satisfying the wait condition used in ",(0,r.kt)("inlineCode",{parentName:"p"},"OSWrappers::waitForVSync"),"."),(0,r.kt)("p",null,"Continuing from the above CMSIS V2 example, the following code puts a message into the message queue\n",(0,r.kt)("inlineCode",{parentName:"p"},"vsync_queue")," which unblocks the TouchGFX Engine."),(0,r.kt)(i.Z,{mdxType:"CodeHeader"},"OSWrappers.cpp (CMSIS V2)"),(0,r.kt)("pre",null,(0,r.kt)("code",g({parentName:"pre"},{className:"language-cpp"}),"void OSWrappers::signalVSync()\n{\n    osMessageQueuePut(vsync_queue, &dummy, 0, 0);\n}\n")),(0,r.kt)("p",null,"This ",(0,r.kt)("inlineCode",{parentName:"p"},"OSWrappers::signalVSync")," method must be called at hardware level from an interrupt for e.g. an LTDC,\nan external signal from the display, or a hardware timer."),(0,r.kt)("p",null,"If not using an RTOS use a variable and assign a non-zero value to break the while-loop."),(0,r.kt)(i.Z,{mdxType:"CodeHeader"},"OSWrappers.cpp (No OS)"),(0,r.kt)("pre",null,(0,r.kt)("code",g({parentName:"pre"},{className:"language-cpp"}),"void OSWrappers::signalVSync()\n{\n    vsync_sem = 1;\n}\n")),(0,r.kt)("h2",g({},{id:"report-touch-and-physical-button-events"}),"Report touch and physical button events"),(0,r.kt)("p",null,"Before rendering a new frame, the TouchGFX Engine collects external input from the ",(0,r.kt)("inlineCode",{parentName:"p"},"TouchController"),"\nand ",(0,r.kt)("inlineCode",{parentName:"p"},"ButtonController")," interfaces."),(0,r.kt)("h3",g({},{id:"touch-coordinates"}),"Touch Coordinates"),(0,r.kt)("p",null,"Coordinates from the touch controller are translated into click-, drag- and gesture\nevents by the TouchGFX Engine and passed to the application. "),(0,r.kt)("p",null,"The way touch coordinated from the touch controller is accessed by the TouchGFX Engine is\nby passing an implementation"),(0,r.kt)("p",null,"The following code is generated\nby the TouchGFX Generator:"),(0,r.kt)(i.Z,{mdxType:"CodeHeader"},"TouchGFXConfiguration.cpp"),(0,r.kt)("pre",null,(0,r.kt)("code",g({parentName:"pre"},{className:"language-cpp",metastring:"{1,3}","{1,3}":!0}),"static STM32TouchController tc;\n...\nstatic TouchGFXHAL hal(dma, display, tc, 390, 390);\n")),(0,r.kt)("p",null,"During the TouchGFX Engine render cycle, when collecting input, the engine calls the ",(0,r.kt)("inlineCode",{parentName:"p"},"sampleTouch()")," function on the ",(0,r.kt)("em",{parentName:"p"},"tc")," object:"),(0,r.kt)("pre",null,(0,r.kt)("code",g({parentName:"pre"},{className:"language-cpp"}),"bool STM32TouchController::sampleTouch(int32_t& x, int32_t& y)\n")),(0,r.kt)("p",null,"The implementation, provided by the AL developer, should assign the read touch coordinate values to x and y and return whether or not a touch was detected (true or false)."),(0,r.kt)(o.Z,{mdxType:"Tip"},"The TouchGFX Generator will generate a class that defines the TouchController interface functions as empty. The HAL developer must fill in the implementation."),(0,r.kt)("p",null,"There are multiple ways of implementing this function:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},(0,r.kt)("em",{parentName:"strong"},"Polling in sampleTouch()")),": Read touch status from the hardware touch controller (typically I2C) by sending a request and polling for the result. This impacts the overall render time of the application as the I2C round-trip is often up to 1 ms during which the graphics engine is blocked."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},(0,r.kt)("em",{parentName:"strong"},"Interrupt based")),": Another possibility is to use interrupts. The I2C read command is started regularly by a timer or as a response to an external interrupt from the touch hardware. When the I2C data is available (another interrupt) the data is made available to the ",(0,r.kt)("inlineCode",{parentName:"li"},"STM32TouchController")," through a message queue or global\nvariables. The code below from ",(0,r.kt)("inlineCode",{parentName:"li"},"STM32TouchController.cpp")," (created by TouchGFX Generator) shows how ",(0,r.kt)("inlineCode",{parentName:"li"},"sampleTouch")," could look for a system with an RTOS:")),(0,r.kt)(i.Z,{mdxType:"CodeHeader"},"STM32TouchController.cpp"),(0,r.kt)("pre",null,(0,r.kt)("code",g({parentName:"pre"},{className:"language-cpp"}),"bool STM32TouchController::sampleTouch(int32_t& x, int32_t& y)\n{\n    if (osMessageQueueGet(mid_MsgQueue, &msg, NULL, 0U) == osOK)\n    {\n        x = msg.x;\n        y = msg.y;\n        return true;\n    }\n    return false;\n}\n")),(0,r.kt)("p",null,"The location of this file will be outlined in the next chapter on TouchGFX Generator"),(0,r.kt)("h3",g({},{id:"other-external-events"}),"Other External Events"),(0,r.kt)("p",null,"The Button Controller interface, ",(0,r.kt)("inlineCode",{parentName:"p"},"touchgfx::ButtonController"),", can be used to map hardware signals (buttons or other) to events to the the application. The reaction to these events can be configured within TouchGFX Designer."),(0,r.kt)("p",null,"The use of this interface is similar to the Touch Controller above, except that it is not mandatory to have a ButtonController. To use it, create an instance of a class implementing the ",(0,r.kt)("inlineCode",{parentName:"p"},"ButtonController")," interface, and pass a reference to the instance to the HAL:"),(0,r.kt)(i.Z,{mdxType:"CodeHeader"},"MyButtonController.cpp"),(0,r.kt)("pre",null,(0,r.kt)("code",g({parentName:"pre"},{className:"language-cpp",metastring:"{3-6}","{3-6}":!0}),"class MyButtonController : public touchgfx::ButtonController\n{\n  bool sample(uint8_t& key)\n  {\n    ... //Sample IO, set key, return true/false\n  }\n};\n")),(0,r.kt)(i.Z,{mdxType:"CodeHeader"},"TouchGFXConfiguration.cpp"),(0,r.kt)("pre",null,(0,r.kt)("code",g({parentName:"pre"},{className:"language-cpp"}),"static MyButtonController bc;\nvoid touchgfx_init()\n{\n  ...\n  hal.initialize();\n  hal.setButtonController(&bc);\n}\n")),(0,r.kt)("p",null,"The ",(0,r.kt)("em",{parentName:"p"},"sample")," method in your ButtonController class is called before each frame. If you return true, the key value will be passed to the ",(0,r.kt)("em",{parentName:"p"},"handleKeyEvent")," eventhandler of the current screen."),(0,r.kt)(l.Z,{mdxType:"FurtherReading"},"See the ",(0,r.kt)(s.Z,{to:"../ui-development/designer-user-guide/interactions-view",mdxType:"Link"},"Interactions")," article for further information on how to use values sampled through the ButtonController as triggers for interactions in the designer."),(0,r.kt)("h2",g({},{id:"synchronize-framebuffer-access"}),"Synchronize framebuffer access"),(0,r.kt)("p",null,"Multiple actors may be interested in accessing the framebuffer memory."),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",g({parentName:"tr"},{align:null})),(0,r.kt)("th",g({parentName:"tr"},{align:null})),(0,r.kt)("th",g({parentName:"tr"},{align:null})))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",g({parentName:"tr"},{align:null}),"1"),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"CPU"),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"Reads and writes pixels during rendering")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",g({parentName:"tr"},{align:null}),"2"),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"DMA2D",(0,r.kt)("strong",{parentName:"td"},"*")),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"Reads and writes pixels during hardware assisted rendering")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",g({parentName:"tr"},{align:null}),"3"),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"LTDC"),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"Reads pixels during transfer to parallel RGB display")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",g({parentName:"tr"},{align:null}),"4"),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"DMA"),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"Read pixels during transfer to SPI display")))),(0,r.kt)("p",null,"The TouchGFX Engine synchronizes framebuffer access through the ",(0,r.kt)("inlineCode",{parentName:"p"},"OSWrappers")," interface and peripherals (e.g. DMA2D) that also wish to access the framebuffer must do the same. The normal design is to use a semaphore to guard the access to the framebuffer, but other synchronization mechanisms can be used."),(0,r.kt)("p",null,"The following table shows a list of functions in the ",(0,r.kt)("inlineCode",{parentName:"p"},"OSWrappers")," class (OSWrappers.cpp) that can be generated by the TouchGFX Generator or manually by the user."),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",g({parentName:"tr"},{align:null}),"Method"),(0,r.kt)("th",g({parentName:"tr"},{align:null}),"Description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",g({parentName:"tr"},{align:null}),(0,r.kt)("inlineCode",{parentName:"td"},"takeFrameBufferSemaphore")),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"Called by graphics engine to get exclusive access to the framebuffer. This will block the engine until the DMA2D is done (if running)")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",g({parentName:"tr"},{align:null}),(0,r.kt)("inlineCode",{parentName:"td"},"tryTakeFrameBufferSemaphore")),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"Ensure that the lock is taken. This method does not block, but ensures that the next call to takeFrameBufferSemaphore will block its caller")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",g({parentName:"tr"},{align:null}),(0,r.kt)("inlineCode",{parentName:"td"},"giveFrameBufferSemaphore")),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"Releases the framebuffer lock")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",g({parentName:"tr"},{align:null}),(0,r.kt)("inlineCode",{parentName:"td"},"giveFrameBufferSemaphoreFromISR")),(0,r.kt)("td",g({parentName:"tr"},{align:null}),"Releases the framebuffer lock from an interrupt context")))),(0,r.kt)(o.Z,{mdxType:"Tip"},"The TouchGFX Generator can generate a ChromART driver that synchronizes using the OSWrappers interface as well as implementations for functions that perform this synchronization depending on choice of RTOS."),(0,r.kt)("h2",g({},{id:"report-the-next-available-framebuffer-area"}),"Report the next available framebuffer area"),(0,r.kt)("p",null,"Regardless of rendering strategy TouchGFX Engine must know, in each tick, which memory area it should render pixels to. Using single- or double framebuffer strategies the TouchGFX Engine will write pixel data to a memory area according to the full width, height, and bit depth, of the framebuffer. The graphics engine takes care of swapping between the two buffers in a double buffer setup."),(0,r.kt)("p",null,"It is possible to limit the access to the framebuffer to part of the framebuffer. The method ",(0,r.kt)("inlineCode",{parentName:"p"},"HAL::getTFTCurrentLine()")," can be reimplemented in your HAL subclass. Return the line number above which it is save for the graphics engine to draw."),(0,r.kt)("p",null,"Using a Partial Framebuffer strategy the developer defines one or more blocks of memory that TouchGFX Engine will use when rendering. Read more about that ",(0,r.kt)("a",g({parentName:"p"},{href:"../scenarios/lowering-memory-usage-with-partial-framebuffer"}),"here"),"."),(0,r.kt)(o.Z,{mdxType:"Tip"},"TouchGFX Generator can provide configurations for all supported framebuffer strategies."),(0,r.kt)("h2",g({},{id:"perform-render-operations"}),"Perform Render Operations"),(0,r.kt)("p",null,"Rendering and displaying graphics are rarely the sole purposes of an application. Other tasks also need to use the CPU. One goal of TouchGFX is to draw the user interface using as few CPU cycles as possible. The HAL class abstracts the DMA2D found on many STM32\nmicrocontrollers (or other hardware capabilities) and makes this available to the graphics engine."),(0,r.kt)("p",null,"When rendering assets such as bitmaps to the framebuffer, the TouchGFX Engine checks if the HAL has the capability to 'blit' a portion of- or all of the bitmap into to the framebuffer. If so, the drawing operation is delegated to the HAL rather than being handled by the CPU."),(0,r.kt)("p",null,"The engine calls the method ",(0,r.kt)("inlineCode",{parentName:"p"},"HAL::getBlitCaps()")," to get a description of the capabilities of the hardware. Your HAL subclass can reimplement this to add the capabilities."),(0,r.kt)("p",null,"When the engine is drawing the user interface it will call operations\non the HAL class, e.g. ",(0,r.kt)("inlineCode",{parentName:"p"},"HAL::blitCopy"),", that queue the operations for\nthe DMA. If the HAL does not report the required capability, the\ngraphics engine will use a software rendering fallback."),(0,r.kt)(o.Z,{mdxType:"Tip"}," Many STM32 MCUs have a ChromART chip which can move data from e.g. external Flash memory into the framebuffer while alpha blending pixels.",(0,r.kt)("p",null,"For many MCUs, TouchGFX Generator can generate a ChromART driver which adds the capability of several 'blit' operations using the ChromART chip.")),(0,r.kt)("h2",g({},{id:"handle-framebuffer-transfer-to-display"}),"Handle framebuffer transfer to display"),(0,r.kt)("p",null,'In order to transfer the framebuffer to the display the hook "Rendering of area complete" is often utilized in a TouchGFX AL.\nThe engine signals the AL once rendering of a part of the framebuffer has been completed. The AL can choose how to transfer this part of the framebuffer to the display.'),(0,r.kt)("h3",g({},{id:"rendering-of-area-complete"}),"Rendering of area complete"),(0,r.kt)("p",null,"In code this hook is the virtual function ",(0,r.kt)("inlineCode",{parentName:"p"},"HAL::flushFrameBuffer(Rect& rect)"),"."),(0,r.kt)("p",null,"On STM32 microcontrollers with LTDC controllers we don't need to do\nanything to transmit the framebuffer after every rendering. This\nhappens continuously with a given frequency after the LTDC has been\ninitialized and therefore we can leave the implementation of this method empty."),(0,r.kt)("p",null,"For other display types like SPI or 8080 you need to transfer the\nframebuffer manually."),(0,r.kt)("p",null,"The implementation of this function allows developers to initiate a manual transfer of that area of the framebuffer to a display with GRAM:"),(0,r.kt)("pre",null,(0,r.kt)("code",g({parentName:"pre"},{className:"language-cpp",metastring:"{9-9}","{9-9}":!0}),"void TouchGFXHAL::flushFrameBuffer(const touchgfx::Rect& r)\n{\n    HAL::flushFrameBuffer(rect); //call superclass\n\n    //start transfer if not running already!\n    if (!IsTransmittingData())\n    {\n        const uint8_t* pixels = ...; // Calculate pixel address\n        SendFrameBufferRect((uint8_t*)pixels, r.x, r.y, r.width, r.height);\n    }\n    else\n    {\n       ... // Queue rect for later or wait here\n    }\n}\n")),(0,r.kt)(l.Z,{mdxType:"FurtherReading"},"Read through the scenarios for concrete examples of how to support various display interfaces."))}N.isMDXComponent=!0}}]);